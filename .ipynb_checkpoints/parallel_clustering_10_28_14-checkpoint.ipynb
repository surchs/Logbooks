{
 "metadata": {
  "name": "",
  "signature": "sha256:8aa05436ab5b4c959ec6ce43fa321ced90fabdb4d42a3ab5e72b78f57347a226"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autosave 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "javascript": [
        "IPython.notebook.set_autosave_interval(100000)"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Autosaving every 100 seconds\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tuesday 28th of October 2014"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Goals for the day:__\n",
      "* <span style=\"color:blue\">Rewrite the clustering routine to run in parallel and potentially make use of grid engine</span>\n",
      "* <span style=\"color:blue\">Search Stackoverflow, make a new post or edit myself the code for sub-subplot generation to automatically generate pyplot axes for visualizing several metrics for one cluster</span>\n",
      "* <span style=\"color:green\">Attempt to send jobs to remote servers from inside the notebook</span>\n",
      "* <span style=\"color:blue\">Make an automated panel of phenotype profiles for a number of subject clusters</span>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Make parallel clustering possible"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calcul Canada is using [moab](https://wiki.calculquebec.ca/w/Moab/en) because why not. So we can submit jobs with the `msub` command to moab. Or we can submit jobs through [Torque](https://wiki.calculquebec.ca/w/Torque/en) using the `qsub` command. Why Torque uses the same commands as the SGE is beyond me but in any case I will have to use system calls to spawn the jobs.\n",
      "\n",
      "Interestingly, I could do all of that [through ssh from my workstation](http://thornelabs.net/2013/08/21/simple-ways-to-send-multiple-line-commands-over-ssh.html) and save the trouble of loging into the clusters directly. This is really nice because then I don't need to start up putty or my vbox. The `-t` option to `ssh` even allows me to [stream](http://unixhelp.ed.ac.uk/CGI/man-cgi?ssh+1) the terminal output."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Send commands to the remote machine through ssh"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(subprocess.check_output(['ssh', '-t', 'gui', 'ls', '-lht']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 0\n",
        "srw-rw---- 1 surchs gsf-624-02   0 Oct  7 04:14 abide\n",
        "drwxr-xr-x 5 surchs gsf-624-02 512 Oct  7 04:06 code\n",
        "drwxrwxr-x 3 surchs gsf-624-02 512 May 20 00:04 Projects\n",
        "srw-rw---- 1 surchs gsf-624-02   0 May 16 09:27 piper\n",
        "drwxrwxr-x 2 surchs gsf-624-02 512 Feb 12  2014 notes\n",
        "-rw-rw-r-- 1 surchs gsf-624-02 113 Feb 12  2014 config\n",
        "lrwxrwxrwx 1 surchs gsf-624-02  19 Feb 12  2014 scratch -> /gs/scratch/surchs/\n",
        "lrwxrwxrwx 1 surchs gsf-624-02  32 Feb 12  2014 database -> /sb/project/gsf-624-aa/database/\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, cool that works well. \n",
      "\n",
      "Now I need a python module that loads the abide data and then spawns a couple of parallel jobs for computing the linkage based on the different networks that I loaded. For the scale 10 Cambridge template that would be 10 jobs, for scale 50 it would be 50 and so on. It's probably not really worth it, seeing that there could be a maximum of 8 parallel jobs on a node but I still want to do it."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Building a python module to handle parallel linkage computation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import nibabel as nib\n",
      "import multiprocessing as mp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build the function\n",
      "def link_network(data, network, method='euclidean', metric=None):\n",
      "    \"\"\"\n",
      "    Create linkage based on maps of one network. If the data array\n",
      "    is oriented the wrong way, this can potentially exceed the available\n",
      "    memory because the distance matrix will be computed across subjects\n",
      "    and not across voxels.\n",
      "    \"\"\"\n",
      "    distance = dist.squareform(dist.pdist(array_dict[metric][..., n_id], 'euclidean'))\n",
      "    linkage = clh.linkage(eucl, method='ward')\n",
      "    \n",
      "    return distance, linkage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.random.random((10,10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = mp.Array('d',a.flatten())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.acquire()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dealing with shared memory inside the loop"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When spawning multiple subprocesses in the node, I don't want to create copies of the input data because it is rather large. The problem seems to be that the [multiprocessing array](https://docs.python.org/2/library/multiprocessing.html#multiprocessing.Array) is an absolute bitch to work with, only accepts 1 dimensional arrays and I have no idea how to read the data in the first place.\n",
      "\n",
      "Ok, [here](http://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-python-multiprocessing) is a nice example. This same page also says that I probably don't have to worry about data being copied at all because things will be forked on linux. I think I'll try that with a quick test.\n",
      "\n",
      "__Goal:__ To run the linkage function on multiple processes while keeping track of memory consumption (if this is possible).\n",
      "\n",
      "__Implementation:__ First I need to wrap my methods into importable packages. This is helpful in general and also the only way to run the memory profiler. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imports\n",
      "import brainbox as bb\n",
      "import multiprocessing as mp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load extensions\n",
      "%load_ext memory_profiler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The memory_profiler extension is already loaded. To reload it, use:\n",
        "  %reload_ext memory_profiler\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Paths\n",
      "debug_path = '/data1/abide/Test/Out/Debug/All'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%memit file_dict = bb.fileOps.grab_files(debug_path, '.nii.gz', 'stability_maps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I will be pulling files from /data1/abide/Test/Out/Debug/All/stability_maps\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I will be pulling files from /data1/abide/Test/Out/Debug/All/stability_maps\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I will be pulling files from /data1/abide/Test/Out/Debug/All/stability_maps\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I will be pulling files from /data1/abide/Test/Out/Debug/All/stability_maps\n",
        "peak memory: 385.69 MiB, increment: 0.11 MiB\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%memit data_dict = bb.fileOps.read_files(file_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "read_files() takes exactly 1 argument (2 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-11-5a235fbca054>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'memit data_dict = bb.fileOps.read_files(file_dict, 100)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/surchs/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2203\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/surchs/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2124\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/surchs/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/memory_profiler.pyc\u001b[0m in \u001b[0;36mmagic_memit\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    775\u001b[0m         tmp = memory_usage((_func_exec, (stmt, self.shell.user_ns)),\n\u001b[0;32m    776\u001b[0m                            \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_usage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m                            include_children=include_children)\n\u001b[0m\u001b[0;32m    778\u001b[0m         \u001b[0mmem_usage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem_usage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/surchs/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/memory_profiler.pyc\u001b[0m in \u001b[0;36mmemory_usage\u001b[1;34m(proc, interval, timeout, timestamps, include_children, max_usage, retval, stream)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# wait until we start getting memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0mreturned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m             \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# finish timing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/surchs/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/memory_profiler.pyc\u001b[0m in \u001b[0;36m_func_exec\u001b[1;34m(stmt, ns)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;31m# helper for magic_memit, just a function proxy for the exec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[1;31m# statement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m     \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;31m# a timeit-style %memit magic for IPython\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: read_files() takes exactly 1 argument (2 given)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def par_link(conf_tuple):\n",
      "    data_dict, network, method, metric = conf_tuple\n",
      "    distance, linkage = bb.dataOps.calc_link(data_dict, network, method='euclidean', metric='stability_maps')\n",
      "    return distance, linkage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare conf\n",
      "conf_list = list()\n",
      "for i in range(10):\n",
      "    conf_list.append((data_dict, i, 'euclidean', 'stability_maps'))    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up parallel run\n",
      "def parallel_run(workers, conf_list):\n",
      "    p = mp.Pool(workers)\n",
      "    par_results = p.map(par_link, conf_list)\n",
      "    return par_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up sequential run\n",
      "def sequential_run(conf_list):\n",
      "    seq_results = []\n",
      "    for conf in conf_list:\n",
      "        seq_results.append(par_link(conf))\n",
      "    return seq_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sequential\n",
      "%memit s_results = sequential_run(conf_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "peak memory: 417.61 MiB, increment: 32.21 MiB\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%memit print('hello')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n",
        "peak memory: 385.49 MiB, increment: 0.02 MiB\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parallel\n",
      "%memit p_results = parallel_run(4, conf_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "peak memory: 997.58 MiB, increment: 612.09 MiB\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%memit print('hello')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hello\n",
        "peak memory: 385.56 MiB, increment: 0.00 MiB\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, I think this is pretty convincing evidence that the parallel jobs copy stuff around and don't just move memory pointers. That's a problem since the raw data for all subjects will be a couple of Gs and then they get bounced around even more. So we should find a way to use shared memory between the processes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processes = [mp.Process(target=par_link, args=(data_dict, i, 'euclidean', 'stability_maps')) for i in xrange(10)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[<Process(Process-46, initial)>,\n",
        " <Process(Process-47, initial)>,\n",
        " <Process(Process-48, initial)>,\n",
        " <Process(Process-49, initial)>,\n",
        " <Process(Process-50, initial)>,\n",
        " <Process(Process-51, initial)>,\n",
        " <Process(Process-52, initial)>,\n",
        " <Process(Process-53, initial)>,\n",
        " <Process(Process-54, initial)>,\n",
        " <Process(Process-55, initial)>]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}